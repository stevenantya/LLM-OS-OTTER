{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from  langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from duckduckgo_search import DDGS\n",
    "import requests\n",
    "import streamlit as st\n",
    "import pymupdf\n",
    "\n",
    "import logging\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('partition_pdf.log'),  # write logs to partition_pdf.log file\n",
    "        logging.StreamHandler()                    # also print logs to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "model = init_chat_model(\"o3-mini\", model_provider=\"openai\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_name = \"Adafruit AHT20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasheet URL: https://cdn-learn.adafruit.com/downloads/pdf/adafruit-aht20.pdf\n",
      "Downloading datasheet...\n",
      "Datasheet already exists in the database.\n",
      "Loading datasheet...\n",
      "Datasheet loaded!\n"
     ]
    }
   ],
   "source": [
    "# Find and download sensor datasheet\n",
    "\n",
    "search_query = f\"{sensor_name} datasheet filetype:pdf\"\n",
    "search_results = DDGS().text(search_query)\n",
    "if search_results:\n",
    "    datasheet_url = search_results[0]['href']\n",
    "    print(f\"Datasheet URL: {datasheet_url}\")\n",
    "    print(\"Downloading datasheet...\")\n",
    "    response = requests.get(datasheet_url)\n",
    "    if response.status_code == 200:\n",
    "        if not os.path.exists(f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_DB/{sensor_name}.pdf\"):     \n",
    "            with open(f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_DB/{sensor_name}.pdf\", \"wb\") as file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    file.write(chunk)\n",
    "            print(\"Datasheet downloaded!\")\n",
    "        else:\n",
    "            print(\"Datasheet already exists in the database.\")\n",
    "    print(\"Loading datasheet...\")\n",
    "    datasheet_path = f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_DB/{sensor_name}.pdf\"\n",
    "    print(\"Datasheet loaded!\")\n",
    "else:\n",
    "    print(\"No datasheet found for this I2C sensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasheet partition exists. Loaded from local file\n"
     ]
    }
   ],
   "source": [
    "# Load and partition the datasheet into elements\n",
    "# 5 levels of partitioning\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import elements_to_dicts, elements_from_dicts\n",
    "import json\n",
    "\n",
    "elements_file_path = f\"/home/steven/FYP/v2_LLM_OS/LLM/Elements_DB/elements_{sensor_name}\"\n",
    "if not os.path.exists(elements_file_path):\n",
    "    elements = partition_pdf(\n",
    "        filename=datasheet_path,\n",
    "\n",
    "        strategy=\"hi_res\",\n",
    "        extract_tables = True,\n",
    "        infer_table_structure=True,\n",
    "        model_name=\"yolox\"\n",
    "    )\n",
    "    elements_dict = elements_to_dicts(elements)\n",
    "    with open(elements_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(elements_dict, f, ensure_ascii=False, indent=4)\n",
    "    print(\"Datasheet Partition does not exist. Created a new parition\")\n",
    "else:\n",
    "    with open(elements_file_path, 'r', encoding='utf-8') as f:\n",
    "        elements_dict = json.load(f)\n",
    "    elements = elements_from_dicts(elements_dict)\n",
    "    print(\"Datasheet partition exists. Loaded from local file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom unstructured.chunking.title import chunk_by_title\\noutput_txt_path = f\\'{sensor_name}_chunks_with_metadata.txt\\'\\n\\nwith open(output_txt_path, \\'w\\', encoding=\\'utf-8\\') as f:\\n    for idx, element in enumerate(elements, 1):\\n        f.write(f\"Chunk {idx}\\n\")\\n        f.write(f\"Type: {element.category}\\n\")\\n\\n        # Include metadata if available\\n        metadata = element.metadata.to_dict() if element.metadata else {}\\n        for key, value in metadata.items():\\n            f.write(f\"{key}: {value}\\n\")\\n\\n        f.write(\"Content:\\n\")\\n        f.write(element.text.strip() + \"\\n\")\\n\\n        f.write(\"\\n----------------------------\\n\\n\")\\n\\nprint(f\"Chunked text with metadata saved to {output_txt_path}\")\\'\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the chunks into file\n",
    "'''\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "output_txt_path = f'{sensor_name}_chunks_with_metadata.txt'\n",
    "\n",
    "with open(output_txt_path, 'w', encoding='utf-8') as f:\n",
    "    for idx, element in enumerate(elements, 1):\n",
    "        f.write(f\"Chunk {idx}\\n\")\n",
    "        f.write(f\"Type: {element.category}\\n\")\n",
    "\n",
    "        # Include metadata if available\n",
    "        metadata = element.metadata.to_dict() if element.metadata else {}\n",
    "        for key, value in metadata.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "        f.write(\"Content:\\n\")\n",
    "        f.write(element.text.strip() + \"\\n\")\n",
    "\n",
    "        f.write(\"\\n----------------------------\\n\\n\")\n",
    "\n",
    "print(f\"Chunked text with metadata saved to {output_txt_path}\")'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove image from the chunk since our current embedding model does not support image\n",
    "elements = [element for element in elements if element.category != 'Image']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit conversion from elements to Langchain Document objects\n",
    "#FIXME: The text output is very small why? The chunk result itself is actually really small T_T\n",
    "#TODO: We might want to combine title and content into one chunk, or delete title category.\n",
    "output_docs_path = f'{sensor_name}_docs_with_metadata.txt'\n",
    "\n",
    "from langchain.schema import Document\n",
    "documents = []\n",
    "with open(output_docs_path, 'w', encoding='utf-8') as f:\n",
    "    for idx, element in enumerate(elements, 1):\n",
    "        f.write(f\"Chunk {idx}\\n\")\n",
    "        metadata = element.metadata.to_dict() if element.metadata else {}\n",
    "        metadata.update({\"type\": element.category})\n",
    "        doc = Document(page_content=element.text.strip(), metadata=metadata)\n",
    "        documents.append(doc)\n",
    "        f.write(f'{element.text} \\n')\n",
    "        f.write(\"\\n---------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB found, loaded from local file\n"
     ]
    }
   ],
   "source": [
    "# Embed the datasheet chunks using FAISS\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "vector_db_path = f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_Vector_DB/{sensor_name}\"\n",
    "if not os.path.exists(vector_db_path):\n",
    "    vector_db = FAISS.from_documents(documents, embeddings)\n",
    "    vector_db.save_local(vector_db_path)\n",
    "    print(\"Vector DB not found, created and saved a new Vector DB\")\n",
    "else:\n",
    "    vector_db = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector DB found, loaded from local file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 10 most similar chunks from the vector DB using cosine simlarity.\n",
    "retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "query = \"I2C address hexadecimal value\"\n",
    "\n",
    "retrieved_chunk = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Chunk 1: The default I2C address is 0x38. It cannot be changed.\n",
      "yes\n",
      "YES. Chunk is helpful, proceeding with the next steps\n",
      "Retrieved Chunk 2: You should see the AHT20's default I2C address of 0x38 pop-up in the I2C scan list.\n",
      "yes\n",
      "YES. Chunk is helpful, proceeding with the next steps\n",
      "Retrieved Chunk 3: I2C Logic Pins\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 4: I don't see the sensor's I2C address listed!\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 5: Here's the Raspberry Pi wired with I2C:\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 6: On the component configuration page, the AHT20's sensor address should be listed along with the sensor's settings.\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 7: • SDA - I2C data pin, connect to your microcontrollers I2C data line. The logic level is the same as VIN. and it has a 10K pullup already on it.\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 8: With the sensor detected in an I2C scan, you're ready to add the sensor to your board.\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 9: • SCL - I2C clock pin, connect to your microcontrollers I2C clock line. The logic level is the same as VIN and it has a 10K pullup already on it.\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 10: This sensor has a typical accuracy of +- 2% relative humidity, and +-0.3 °C. There is only one I2C address so its not a good option when you need multiple humidity sensors.\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the chunks. Ask the LLM if the chunk is helpful for answering the query. (Chunk validation)\n",
    "# How do I ask LLM if the chunk is helpful, if not mark the chunk as not helpful and retrieve the next chunk?\n",
    "validation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant that validates if a provided document chunk is helpful in answering the user's query.\n",
    "\n",
    "    QUERY:\n",
    "    {query}\n",
    "\n",
    "    CHUNK:\n",
    "    {chunk}\n",
    "\n",
    "    Is this chunk helpful for answering the query? Respond ONLY with 'Yes' or 'No'.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "validated_chunks = []\n",
    "\n",
    "# Inspect the retrieved chunks (optional, for debugging purposes)\n",
    "for idx, chunk in enumerate(retrieved_chunk):\n",
    "    print(f\"Retrieved Chunk {idx+1}: {chunk.page_content}\")\n",
    "    prompt = validation_prompt.format_messages(query=query, chunk=chunk.page_content)\n",
    "    # print(prompt)\n",
    "    response = model.invoke(prompt).content.strip().lower()\n",
    "    print(response)\n",
    "    if 'yes' in response:\n",
    "        validated_chunks.append(chunk)\n",
    "        print(\"YES. Chunk is helpful, proceeding with the next steps\")\n",
    "    else:\n",
    "        print(\"NO. Chunk not helpful, moving to next chunk\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated Chunks: The default I2C address is 0x38. It cannot be changed.\n",
      "You should see the AHT20's default I2C address of 0x38 pop-up in the I2C scan list.\n",
      "\n",
      "Response: 0x38\n"
     ]
    }
   ],
   "source": [
    "# Consolidate the validated chunks\n",
    "consolidated_chunks = \"\"\n",
    "for chunk in validated_chunks:\n",
    "    consolidated_chunks += f\"{chunk.page_content}\\n\"\n",
    "\n",
    "print(f\"Consolidated Chunks: {consolidated_chunks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the LLM to extract the I2C address from the consolidated chunks\n",
    "prompt_i2c_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant that returns the hexadecimal address of the I2C sensor.\n",
    "\n",
    "    Helpful context:\n",
    "    {chunk}\n",
    "\n",
    "    From your knowledge, what is the I2C address of {sensor_name}? Respond ONLY the hexadecimal value.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt_i2c = prompt_i2c_template.format_messages(\n",
    "    chunk=consolidated_chunks,\n",
    "    sensor_name=sensor_name\n",
    ")\n",
    "\n",
    "response = model.invoke(prompt_i2c).content.strip()\n",
    "print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
