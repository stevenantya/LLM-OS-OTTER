{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from  langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from duckduckgo_search import DDGS\n",
    "import requests\n",
    "import streamlit as st\n",
    "import pymupdf\n",
    "\n",
    "import logging\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('partition_pdf.log'),  # write logs to partition_pdf.log file\n",
    "        logging.StreamHandler()                    # also print logs to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "model = init_chat_model(\"o3-mini\", model_provider=\"openai\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_name = \"MCP9808\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasheet URL: https://cdn-shop.adafruit.com/datasheets/MCP9808.pdf\n",
      "Downloading datasheet...\n",
      "Datasheet already exists in the database.\n",
      "Loading datasheet...\n",
      "Datasheet loaded!\n"
     ]
    }
   ],
   "source": [
    "# Find and download sensor datasheet\n",
    "\n",
    "search_query = f\"{sensor_name} datasheet filetype:pdf\"\n",
    "search_results = DDGS().text(search_query)\n",
    "if search_results:\n",
    "    datasheet_url = search_results[0]['href']\n",
    "    print(f\"Datasheet URL: {datasheet_url}\")\n",
    "    print(\"Downloading datasheet...\")\n",
    "    response = requests.get(datasheet_url)\n",
    "    if response.status_code == 200:\n",
    "        if not os.path.exists(f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_DB/{sensor_name}.pdf\"):     \n",
    "            with open(f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_DB/{sensor_name}.pdf\", \"wb\") as file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    file.write(chunk)\n",
    "            print(\"Datasheet downloaded!\")\n",
    "        else:\n",
    "            print(\"Datasheet already exists in the database.\")\n",
    "    print(\"Loading datasheet...\")\n",
    "    datasheet_path = f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_DB/{sensor_name}.pdf\"\n",
    "    print(\"Datasheet loaded!\")\n",
    "else:\n",
    "    print(\"No datasheet found for this I2C sensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasheet partition exists. Loaded from local file\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "# Load and partition the datasheet into elements\n",
    "# 5 levels of partitioning\n",
    "import pymupdf4llm\n",
    "import pathlib\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "md_path = f\"/home/steven/FYP/v2_LLM_OS/LLM/MD_DB/md_{sensor_name}.md\"\n",
    "if not os.path.exists(md_path):\n",
    "    md_text = pymupdf4llm.to_markdown(datasheet_path)\n",
    "    pathlib.Path(md_path).write_bytes(md_text.encode())\n",
    "    print(\"Datasheet Partition does not exist. Created a new parition\")\n",
    "else:\n",
    "    md_text = pathlib.Path(md_path).read_text()\n",
    "    print(\"Datasheet partition exists. Loaded from local file\")\n",
    "\n",
    "splitter = MarkdownTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "docs = splitter.create_documents([md_text])\n",
    "\n",
    "print(len(docs))\n",
    "# Join all document contents into one string\n",
    "all_text = \"\\n\\n---------XXXX----------\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Save to a single file\n",
    "output_file = f\"/home/steven/FYP/v2_LLM_OS/LLM/MD_DB/split_md_{sensor_name}.md\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB found, loaded from local file\n"
     ]
    }
   ],
   "source": [
    "# Embed the datasheet chunks using FAISS\n",
    "#TODO: We might want to use multiple datasheets for the same sensor\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "vector_db_path = f\"/home/steven/FYP/v2_LLM_OS/LLM/Datasheet_Vector_DB/{sensor_name}\"\n",
    "if not os.path.exists(vector_db_path):\n",
    "    vector_db = FAISS.from_documents(docs, embeddings)\n",
    "    vector_db.save_local(vector_db_path)\n",
    "    print(\"Vector DB not found, created and saved a new Vector DB\")\n",
    "else:\n",
    "    vector_db = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector DB found, loaded from local file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 10 most similar chunks from the vector DB using cosine simlarity.\n",
    "retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "query = \"Trigger measurement read command hexadecimal value\" \n",
    "\n",
    "retrieved_chunk = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Chunk 1: |0x02|T UPPER|0x0000|0°C|\n",
      "|0x03|T LOWER|0x0000|0°C|\n",
      "|0x04|T CRIT|0x0000|0°C|\n",
      "|0x05|T A|0x0000|0°C|\n",
      "|0x06|Manufacturer ID|0x0054|0x0054 (hex)|\n",
      "|0x07|Device ID/Device Revision|0x0400|0x0400 (hex)|\n",
      "|0x08|Resolution|0x03|0x03 (hex)|\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 2: ```\n",
      "                           //also, make sure bit 0 is Set ‘1’\n",
      "     UpperByte = i2c_read(ACK); // READ 8 bits\n",
      "                           //and Send ACK bit\n",
      "     LowerByte = i2c_read(NAK); // READ 8 bits\n",
      "                           //and Send NAK bit\n",
      "     i2c_stop(); // send STOP command\n",
      "     //Convert the temperature data\n",
      "     //First Check flag bits\n",
      "     if ((UpperByte & 0x80) == 0x80){ //T A ³ T CRIT\n",
      "     }\n",
      "     if ((UpperByte & 0x40) == 0x40){ //T A > T UPPER\n",
      "     }\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n",
      "Retrieved Chunk 3: Shutdown\n",
      "\n",
      "Critical Trip Lock\n",
      "\n",
      "Alarm Window Lock\n",
      "\n",
      "Clear Alert\n",
      "\n",
      "Alert Status\n",
      "\n",
      "Output Control\n",
      "\n",
      "Critical Alert only\n",
      "\n",
      "Alert Polarity\n",
      "\n",
      "Alert Comp./Int.\n",
      "\n",
      "Configuration\n",
      "\n",
      "Tem p erature\n",
      "\n",
      "T UPPER Limit\n",
      "\n",
      "T LOWER Limit\n",
      "\n",
      "T CRITICAL Limit\n",
      "\n",
      "Manufacturer ID\n",
      "\n",
      "Device ID/Rev\n",
      "\n",
      "Resolution\n",
      "\n",
      "SMBus/Standard I [2] C™\n",
      "Interface\n",
      "\n",
      "\n",
      "Band Gap\n",
      "Temperature\n",
      "Sensor\n",
      "\n",
      "ΔΣ ADC\n",
      "\n",
      "+0.5°C\n",
      "+0.25°C\n",
      "+0.125°C\n",
      "+0.0625°C\n",
      "\n",
      "\n",
      "A0 A1 A2 Alert SDA SCL V DD GND\n",
      "\n",
      "DS25095A-page 2 © 2011 Microchip Technology Inc.\n",
      "\n",
      "\n",
      "-----\n",
      "no\n",
      "NO. Chunk not helpful, moving to next chunk\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the chunks. Ask the LLM if the chunk is helpful for answering the query. (Chunk validation)\n",
    "# How do I ask LLM if the chunk is helpful, if not mark the chunk as not helpful and retrieve the next chunk?\n",
    "validation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant that validates if a provided document chunk is helpful in answering the user's query.\n",
    "\n",
    "    QUERY:\n",
    "    {query}\n",
    "\n",
    "    CHUNK:\n",
    "    {chunk}\n",
    "\n",
    "    Is this chunk helpful for answering the query? Respond ONLY with 'Yes' or 'No'.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "validated_chunks = []\n",
    "\n",
    "# Inspect the retrieved chunks (optional, for debugging purposes)\n",
    "for idx, chunk in enumerate(retrieved_chunk):\n",
    "    print(f\"Retrieved Chunk {idx+1}: {chunk.page_content}\")\n",
    "    prompt = validation_prompt.format_messages(query=query, chunk=chunk.page_content)\n",
    "    # print(prompt)\n",
    "    response = model.invoke(prompt).content.strip().lower()\n",
    "    print(response)\n",
    "    if 'yes' in response:\n",
    "        validated_chunks.append(chunk)\n",
    "        print(\"YES. Chunk is helpful, proceeding with the next steps\")\n",
    "    else:\n",
    "        print(\"NO. Chunk not helpful, moving to next chunk\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated Chunks: \n"
     ]
    }
   ],
   "source": [
    "# Consolidate the validated chunks\n",
    "consolidated_chunks = \"\"\n",
    "i = 1\n",
    "for chunk in validated_chunks:\n",
    "    consolidated_chunks += f\"{i}. {chunk.page_content}\\n\"\n",
    "    i += 1\n",
    "    \n",
    "print(f\"Consolidated Chunks: {consolidated_chunks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I'll explain my reasoning:\n",
      "\n",
      "1. • First, I recalled that the MCP9808 is designed to operate in continuous conversion mode. That means it continuously measures temperature and updates its internal temperature register without needing an explicit “trigger conversion” command.\n",
      "\n",
      "2. • Next, I noted that for many I²C temperature sensors, one common approach (if a trigger were needed) is to write a pointer register value to select the temperature register and then perform a read transaction. In the case of the MCP9808, the temperature register is the one you want to access (its default pointer is set for the ambient temperature register).\n",
      "\n",
      "3. • However, because the MCP9808 performs conversions continuously, there isn’t a separate command you must issue to trigger a new measurement. Instead, a typical operation consists of ensuring the pointer register is set to the ambient temperature register (which is often already the default) and then simply reading the two bytes of temperature data via an I²C read transaction.\n",
      "\n",
      "4. • Therefore, the “trigger measurement” step is not needed as it is with some sensors that require an explicit start-conversion command.\n",
      "\n",
      "So, in summary, the MCP9808 does not require any explicit “trigger measurement read command.” You simply read the temperature register (usually by writing its register pointer if needed and then reading two bytes), and the sensor’s continuous conversion mode automatically provides the latest temperature measurement.\n",
      "\n",
      "That’s why there is no separate trigger command—it isn’t needed.\n"
     ]
    }
   ],
   "source": [
    "# Chain of Thought Reasoning LLM to extract the I2C address from the consolidated chunks\n",
    "# https://www.datacamp.com/tutorial/chain-of-thought-prompting\n",
    "prompt_i2c_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant and an expert in I2C sensors.\n",
    "\n",
    "    Raw context:\n",
    "    {chunk}\n",
    "\n",
    "    From your knowledge, what is the trigger measurement read commands of {sensor_name}? Show me the reasoning process step by step and use your memory.\n",
    "    If it is not needed, please say so.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt_i2c = prompt_i2c_template.format_messages(\n",
    "    chunk=consolidated_chunks,\n",
    "    sensor_name=sensor_name\n",
    ")\n",
    "\n",
    "CoT_response = model.invoke(prompt_i2c).content.strip()\n",
    "print(f\"Response: {CoT_response}\")\n",
    "\n",
    "# The context is correct. The output is wrong, but in chatgpt website, the output is correct.\n",
    "# Maybe they are using reasoning and chain of thought which might be super helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Since the sensor continuously converts the temperature without needing a trigger command, no special hexadecimal command is required to initiate a measurement. In fact, you typically just ensure the pointer is set to the ambient temperature register (which is often already the default) and then perform a read transaction to receive the two temperature data bytes.\n",
      "\n",
      "Thus, the hexadecimal values are: INOP\n"
     ]
    }
   ],
   "source": [
    "prompt_i2c_feedback_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant and an expert in I2C Sensors.\n",
    "\n",
    "    My expert told me:\n",
    "    {i2c_CoT_response}\n",
    "\n",
    "    What are the hexadecimal values to write to the i2c address to trigger measurement or read data from {sensor_name} sensor?\n",
    "    If it is not needed, output \"INOP\".\n",
    "    Finish the sentence, the hexadecimal values are:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt_i2c_feedback = prompt_i2c_feedback_template.format_messages(\n",
    "    i2c_CoT_response=CoT_response,\n",
    "    sensor_name=sensor_name\n",
    ")\n",
    "i2c_feedback_response = model.invoke(prompt_i2c_feedback).content.strip()\n",
    "print(f\"Response: {i2c_feedback_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No initialization needed\n"
     ]
    }
   ],
   "source": [
    "if \"INOP\" in i2c_feedback_response:\n",
    "    print(\"No initialization needed\")\n",
    "else:\n",
    "    prompt_i2c_cleanup_template = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are a helpful assistant and hexadecimal values extractor.\n",
    "\n",
    "        My expert told me:\n",
    "        {i2c_feedback_response}\n",
    "\n",
    "        Extract only the hexadecimal values separated by commas.\n",
    "        \"\"\"\n",
    "    )\n",
    "    prompt_i2c_cleanup = prompt_i2c_cleanup_template.format_messages(\n",
    "        i2c_feedback_response=i2c_feedback_response\n",
    "    )\n",
    "    i2c_cleanup_response = model.invoke(prompt_i2c_cleanup).content.strip()\n",
    "    print(f\"Response: {i2c_cleanup_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
